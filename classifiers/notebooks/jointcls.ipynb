{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d79477-c5d4-428e-bbcf-c2e3b0002389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U -q torchmetrics transformers wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2dc436-9368-42e0-923c-96ea56d18374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import (TensorDataset,\n",
    "                              Dataset,\n",
    "                              DataLoader,\n",
    "                              RandomSampler,\n",
    "                              SequentialSampler)\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup, set_seed\n",
    "import torchmetrics\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6a7420-f9e2-4d3d-a630-d2cdf297220a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ca81a1-c0f3-46b3-9cb1-04dd9b61e91d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cfa9e6-07d6-4a9a-913f-eae1cff08d75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 25 07:16:48 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   24C    P8              16W / 300W |      2MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb81bf8-ece4-4488-8065-89871dd241e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918a545a-a2e6-4902-a667-a765c43513c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Исполнитель</th>\n",
       "      <th>Группа тем</th>\n",
       "      <th>Текст инцидента</th>\n",
       "      <th>Тема</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Лысьвенский городской округ</td>\n",
       "      <td>Благоустройство</td>\n",
       "      <td>Сегодня, 20.08.22, моя мать шла по улице Ленин...</td>\n",
       "      <td>★ Ямы во дворах</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Министерство социального развития ПК</td>\n",
       "      <td>Социальное обслуживание и защита</td>\n",
       "      <td>Пермь г, +79194692145. В Перми с ноября 2021 г...</td>\n",
       "      <td>Оказание гос. соц. помощи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Министерство социального развития ПК</td>\n",
       "      <td>Социальное обслуживание и защита</td>\n",
       "      <td>Скажите пожалуйста если подовала на пособие с ...</td>\n",
       "      <td>Дети и многодетные семьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Город Пермь</td>\n",
       "      <td>Общественный транспорт</td>\n",
       "      <td>Каждая из них не о чем. Люди на остановках хот...</td>\n",
       "      <td>Содержание остановок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Министерство здравоохранения</td>\n",
       "      <td>Здравоохранение/Медицина</td>\n",
       "      <td>В Березниках у сына привитого откоронавируса з...</td>\n",
       "      <td>Технические проблемы с записью на прием к врачу</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Исполнитель                        Группа тем  \\\n",
       "0           Лысьвенский городской округ                   Благоустройство   \n",
       "1  Министерство социального развития ПК  Социальное обслуживание и защита   \n",
       "2  Министерство социального развития ПК  Социальное обслуживание и защита   \n",
       "3                           Город Пермь            Общественный транспорт   \n",
       "4          Министерство здравоохранения          Здравоохранение/Медицина   \n",
       "\n",
       "                                     Текст инцидента  \\\n",
       "0  Сегодня, 20.08.22, моя мать шла по улице Ленин...   \n",
       "1  Пермь г, +79194692145. В Перми с ноября 2021 г...   \n",
       "2  Скажите пожалуйста если подовала на пособие с ...   \n",
       "3  Каждая из них не о чем. Люди на остановках хот...   \n",
       "4  В Березниках у сына привитого откоронавируса з...   \n",
       "\n",
       "                                              Тема  \n",
       "0                                  ★ Ямы во дворах  \n",
       "1                        Оказание гос. соц. помощи  \n",
       "2                         Дети и многодетные семьи  \n",
       "3                             Содержание остановок  \n",
       "4  Технические проблемы с записью на прием к врачу  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86568ac-0b10-42af-8d66-56dcc9e8ba79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "executor_label = df['Исполнитель'].unique().tolist()\n",
    "theme_group_label = df['Группа тем'].unique().tolist()\n",
    "theme_label = df['Тема'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a5790e-7440-48c7-ac7c-2291a10258f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "executor2idx = {l:i for i, l in enumerate(executor_label)}\n",
    "theme_group2idx = {l:i for i, l in enumerate(theme_group_label)}\n",
    "theme2idx = {l:i for i, l in enumerate(theme_label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb97374-7833-4661-ab23-13a01f2207c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA A10G\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "print(device.type)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103f0e19-49bb-4044-8052-5110c92f9543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ai-forever/ruBert-large'\n",
    "SEED = 42\n",
    "EPOCHS = 16\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 3e-5\n",
    "MAX_LEN = 390\n",
    "DROPOUT = .1\n",
    "WARMUP_STEPS = 0.1\n",
    "\n",
    "set_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca81a254-1476-405d-9ade-47f4c8a9bac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tensors(texts, executor_labels, theme_group_labels, theme_labels):\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt')\n",
    "    executor_labels = [executor2idx[l] for l in executor_labels]\n",
    "    theme_group_labels = [theme_group2idx[l] for l in theme_group_labels]\n",
    "    theme_labels = [theme2idx[l] for l in theme_labels]\n",
    "\n",
    "    executor_labels = torch.tensor(executor_labels, dtype=torch.long)\n",
    "    theme_group_labels = torch.tensor(theme_group_labels, dtype=torch.long)\n",
    "    theme_labels = torch.tensor(theme_labels, dtype=torch.long)\n",
    "\n",
    "    # assert len(inputs) == len(executor_labels) == len(theme_group_labels) == len(theme_labels)\n",
    "    return inputs['input_ids'], inputs['attention_mask'], executor_labels, theme_group_labels, theme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7d3ba6-aba1-494e-9ec2-a5010a42940b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JointClassifier(nn.Module):\n",
    "    def __init__(self, model_name: str = 'ai-forever/ruBert-large', dropout: float = .1):\n",
    "        super(JointClassifier, self).__init__()\n",
    "        self.language_model = BertModel.from_pretrained(model_name)\n",
    "        self.executor_cls = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1024, len(executor_label)),\n",
    "        )\n",
    "        self.theme_group_cls = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1024, len(theme_group_label)),\n",
    "        )\n",
    "        self.theme_cls = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024 + len(theme_group_label)),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1024 + len(theme_group_label), len(theme_label)),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.language_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        executor_logits = self.executor_cls(output)\n",
    "        theme_group_logits = self.theme_group_cls(output)\n",
    "        theme_inputs = torch.cat(\n",
    "            (output, theme_group_logits), 1\n",
    "        )\n",
    "        theme_logits = self.theme_cls(theme_inputs)\n",
    "        return executor_logits, theme_group_logits, theme_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2712bf0b-9895-4641-bd81-7de7c396d9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    executor_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(executor_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    theme_group_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(theme_group_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    theme_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(theme_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    for input_ids, attention_mask, executor_labels, theme_group_labels, theme_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        executor_logits, theme_group_logits, theme_logits = model(input_ids.to(device), attention_mask.to(device))\n",
    "        executor_loss = criterion(executor_logits, executor_labels.to(device))\n",
    "        theme_group_loss = criterion(theme_group_logits, theme_group_labels.to(device))\n",
    "        theme_loss = criterion(theme_logits, theme_labels.to(device))\n",
    "        loss = (executor_loss + theme_group_loss + theme_loss) / 3\n",
    "        wandb.log({'step_loss': loss.item()})\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        executor_preds = torch.argmax(torch.softmax(executor_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "        theme_group_preds = torch.argmax(torch.softmax(theme_group_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "        theme_preds = torch.argmax(torch.softmax(theme_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "\n",
    "        wandb.log({'executor_F1': executor_F1(executor_preds, executor_labels).item()})\n",
    "        wandb.log({'theme_group_F1': theme_group_F1(theme_group_preds, theme_group_labels).item()})\n",
    "        wandb.log({'theme_F1': theme_F1(theme_preds, theme_labels).item()})\n",
    "        \n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if WARMUP_STEPS > 0:\n",
    "            scheduler.step()\n",
    "    \n",
    "    total_loss /= len(train_dataloader)\n",
    "    wandb.log({'epoch_train_loss': total_loss})\n",
    "    wandb.log({'epoch_train_executor_F1': executor_F1.compute().item()})\n",
    "    wandb.log({'epoch_train_theme_group_F1': theme_group_F1.compute().item()})\n",
    "    wandb.log({'epoch_train_theme_F1': theme_F1.compute().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0ed3ff-7d22-4aa3-9906-e6fb09a6bdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    executor_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(executor_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    theme_group_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(theme_group_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    theme_F1 = torchmetrics.classification.MulticlassF1Score(\n",
    "        num_classes=len(theme_label),\n",
    "        average='weighted'\n",
    "    )\n",
    "    for input_ids, attention_mask, executor_labels, theme_group_labels, theme_labels in test_dataloader:\n",
    "        executor_logits, theme_group_logits, theme_logits = model(input_ids.to(device), attention_mask.to(device))\n",
    "        executor_loss = criterion(executor_logits, executor_labels.to(device))\n",
    "        theme_group_loss = criterion(theme_group_logits, theme_group_labels.to(device))\n",
    "        theme_loss = criterion(theme_logits, theme_labels.to(device))\n",
    "        loss = (executor_loss + theme_group_loss + theme_loss) / 3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        executor_preds = torch.argmax(torch.softmax(executor_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "        theme_group_preds = torch.argmax(torch.softmax(theme_group_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "        theme_preds = torch.argmax(torch.softmax(theme_logits.detach().cpu(), dim=-1), dim=-1)\n",
    "\n",
    "        executor_F1(executor_preds, executor_labels)\n",
    "        theme_group_F1(theme_group_preds, theme_group_labels)\n",
    "        theme_F1(theme_preds, theme_labels)\n",
    "    total_loss /= len(test_dataloader)\n",
    "    wandb.log({'epoch_test_loss': total_loss})\n",
    "    wandb.log({'epoch_test_executor_F1': executor_F1.compute().item()})\n",
    "    wandb.log({'epoch_test_theme_group_F1': theme_group_F1.compute().item()})\n",
    "    wandb.log({'epoch_test_theme_F1': theme_F1.compute().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0a83e1-0d24-47bb-a3f1-dd3ecc0bde4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7f2a7e-feef-442f-b167-e8187f6df095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=SEED, test_size=.1, stratify=df['Тема'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db07e50-4cf3-4116-9e43-00b4550fb97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# texts, executor_labels, theme_group_labels, theme_labels\n",
    "train_data = TensorDataset(*get_tensors(\n",
    "    df_train['Текст инцидента'].to_list(),\n",
    "    df_train['Исполнитель'].to_list(),\n",
    "    df_train['Группа тем'].to_list(),\n",
    "    df_train['Тема'].to_list()\n",
    "    ))\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_data = TensorDataset(*get_tensors(\n",
    "    df_test['Текст инцидента'].to_list(),\n",
    "    df_test['Исполнитель'].to_list(),\n",
    "    df_test['Группа тем'].to_list(),\n",
    "    df_test['Тема'].to_list()\n",
    "))\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    sampler=SequentialSampler(test_data),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1141d80f-4d9c-411b-9af1-e7edfb681cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = JointClassifier()\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "if WARMUP_STEPS > 0:\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=len(train_dataloader) * WARMUP_STEPS * EPOCHS,\n",
    "        num_training_steps=len(train_dataloader) * EPOCHS\n",
    "    )\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff9a7b2-9979-4b36-abfb-9673a075c27e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mblanchefort\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b54c79-9768-4f5f-bfd7-9f843a1eafc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/notebooks/wandb/run-20231125_080954-g09zbo4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/blanchefort/loon-bit-loop-text-classifier/runs/g09zbo4n' target=\"_blank\">cerulean-mountain-28</a></strong> to <a href='https://wandb.ai/blanchefort/loon-bit-loop-text-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/blanchefort/loon-bit-loop-text-classifier' target=\"_blank\">https://wandb.ai/blanchefort/loon-bit-loop-text-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/blanchefort/loon-bit-loop-text-classifier/runs/g09zbo4n' target=\"_blank\">https://wandb.ai/blanchefort/loon-bit-loop-text-classifier/runs/g09zbo4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/blanchefort/loon-bit-loop-text-classifier/runs/g09zbo4n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fcaf3b0f970>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='loon-bit-loop-text-classifier'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43abde-282c-4466-8fdf-d464e2b6dace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "for epoch in range(EPOCHS):\n",
    "    train()\n",
    "    evaluate()\n",
    "    model.to('cpu')\n",
    "    path = f'../models/{epoch}.pt'\n",
    "    torch.save(model.state_dict(), path)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27780dd5-7b42-4c40-9477-a666d595cb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0e86f-a26c-436c-9fd8-d8203b96786e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
